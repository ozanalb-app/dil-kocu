import streamlit as st
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import streamlit.components.v1 as components
import io

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="Pro Dil KoÃ§u (Whisper)", page_icon="ğŸ§")

st.title("ğŸ§ Pro Dil KoÃ§u (YÃ¼ksek Kalite)")
st.info("Bu mod OpenAI Whisper kullanÄ±r. AksanÄ±nÄ±zÄ± ve hatalarÄ±nÄ±zÄ± Ã§ok daha iyi anlar.")

# --- AYARLAR ---
with st.sidebar:
    api_key = st.text_input("OpenAI API Key", type="password")
    dil = st.radio("Dil SeÃ§imi", ["Ä°ngilizce", "TÃ¼rkÃ§e"])
    lang_code = "en" if dil == "Ä°ngilizce" else "tr"

# --- TTS (SESLENDÄ°RME) ---
def speak(text, lang):
    js = f"""
    <script>
        window.speechSynthesis.cancel();
        var msg = new SpeechSynthesisUtterance("{text.replace('"', '')}");
        msg.lang = "{'en-US' if lang == 'en' else 'tr-TR'}";
        window.speechSynthesis.speak(msg);
    </script>
    """
    components.html(js, height=0)

# --- ANA AKIÅ ---
if api_key:
    client = OpenAI(api_key=api_key)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # SOHBETÄ° GÃ–STER
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # --- MÄ°KROFON (KAYIT ALIP GÃ–NDERME) ---
    st.write("---")
    st.write("Mikrofona basÄ±n, konuÅŸun ve durdurun:")
    
    # Sesi dosya olarak alÄ±yoruz (Bytes)
    audio = mic_recorder(
        start_prompt="ğŸ”´ KaydÄ± BaÅŸlat",
        stop_prompt="â¹ï¸ Bitir ve GÃ¶nder",
        key="recorder"
    )

    if audio:
        # Sesi OpenAI Whisper'a gÃ¶nderiyoruz
        with st.spinner("Sesiniz analiz ediliyor (Whisper)..."):
            audio_bio = io.BytesIO(audio['bytes'])
            audio_bio.name = "audio.webm"
            
            # KÃœÃ‡ÃœK AMA ETKÄ°LÄ° DOKUNUÅ: 'prompt' parametresini ekledik.
            # Modele "Bu bir dil Ã¶ÄŸrenme seansÄ±" diyerek ipucu veriyoruz.
            context_prompt = "This is a language learning session. The user might have an accent."
            
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_bio,
                language=lang_code,
                prompt=context_prompt 
            )
            user_text = transcript.text

        # EÄŸer yeni bir ÅŸey sÃ¶ylediyse iÅŸle
        if not st.session_state.messages or st.session_state.messages[-1]["content"] != user_text:
            
            # KullanÄ±cÄ± mesajÄ±
            st.session_state.messages.append({"role": "user", "content": user_text})
            with st.chat_message("user"):
                st.write(user_text)

            # GPT CevabÄ±
            with st.chat_message("assistant"):
                with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                    system_msg = f"Sen {dil} Ã¶ÄŸreten, B1 seviyesinde konuÅŸan sabÄ±rlÄ± bir Ã¶ÄŸretmensin. HatalarÄ± dÃ¼zelt."
                    
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "system", "content": system_msg}] + st.session_state.messages
                    )
                    reply = response.choices[0].message.content
                    
                    st.write(reply)
                    st.session_state.messages.append({"role": "assistant", "content": reply})
                    
                    # Seslendir
                    speak(reply, lang_code)

else:
    st.warning("LÃ¼tfen API anahtarÄ±nÄ± girin.")